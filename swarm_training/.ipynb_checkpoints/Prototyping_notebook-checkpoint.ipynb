{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM adversary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# dataset\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "# tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# Parameters\n",
    "nAgents = 6\n",
    "obsDim = 2\n",
    "inpDim = nAgents*obsDim\n",
    "hiddenDim = 2*nAgents\n",
    "outDim = nAgents\n",
    "initSteps = 10\n",
    "batch_size = 20\n",
    "val_frac = 0.2\n",
    "\n",
    "\n",
    "\n",
    "class TrajDataset(Dataset):\n",
    "    # swarm trajectory dataset                                      \n",
    "    def __init__(self, root_dir, num_agents, obs_dim, init_steps, mode = 'HDD'):\n",
    "        self.root_dir = root_dir\n",
    "        self.files = [os.path.join(self.root_dir,f) for f in os.listdir(self.root_dir)]\n",
    "        self.num_files = len(self.files)\n",
    "        self.num_agents = num_agents\n",
    "        self.obs_dim = obs_dim\n",
    "        self.init_steps = init_steps\n",
    "        self.mode = mode\n",
    "        if self.mode == 'RAM':\n",
    "            print('mode is ram')\n",
    "            self.X = []\n",
    "            self.Y = []\n",
    "            for i in range(self.num_files):\n",
    "                file = self.files[i]\n",
    "                data = np.load(file)\n",
    "                X,Y = data[:,:-1], data[:,-1]\n",
    "                X,Y = self.transform(X,Y)\n",
    "                self.X.append(X.view(1,51,12))\n",
    "                self.Y.append(Y.view(1,-1))\n",
    "            self.X = torch.from_numpy(np.vstack(self.X))\n",
    "            self.Y = torch.from_numpy(np.vstack(self.Y))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_files\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == 'RAM':\n",
    "            return(self.X[idx], self.Y[idx])\n",
    "        else:\n",
    "            file = self.files[idx]\n",
    "            data = np.load(file)\n",
    "            X,Y = data[:,:-1], data[:,-1]\n",
    "            X,Y = self.transform(X,Y)\n",
    "            return X,Y\n",
    "    \n",
    "    def transform(self, X, Y):\n",
    "        # select random location for leader\n",
    "        i = np.random.randint(self.num_agents)\n",
    "        \n",
    "        temp = X[:,i*self.obs_dim:(i+1)*self.obs_dim].copy()\n",
    "        X[:,i*self.obs_dim:(i+1)*self.obs_dim] = X[:,0:self.obs_dim].copy()\n",
    "        X[:,0:self.obs_dim] = temp.copy()\n",
    "        \n",
    "        Y[:] = i\n",
    "        Y = Y[self.init_steps:]\n",
    "        \n",
    "        X,Y = torch.tensor(X, dtype = torch.float32),torch.tensor(Y, dtype = torch.int64)\n",
    "        return(X,Y)\n",
    "        \n",
    "\n",
    "# Setup model\n",
    "class adversaryNet(nn.Module):\n",
    "    def __init__(self, inpDim, hiddenDim, outDim, initSteps):\n",
    "        super(adversaryNet, self).__init__()\n",
    "        self.inpDim = inpDim\n",
    "        self.hiddenDim = hiddenDim\n",
    "        self.outDim = outDim\n",
    "        self.initSteps = initSteps                     \n",
    "        self.lstm1 = nn.LSTM(inpDim, hiddenDim)           # Input dim is 3, output dim is 3\n",
    "        self.lstm2 = nn.LSTM(hiddenDim, hiddenDim)\n",
    "        self.fc1 = nn.Linear(hiddenDim, outDim)\n",
    "#         self.fc2 = nn.Linear(hiddenDim, outDim)\n",
    "        \n",
    "    def forward(self,x):  # x in shape [batch_size, seq_len, inp_dim]\n",
    "        batchSize, seqLen, _ = x.shape\n",
    "        \n",
    "        # reshape,feed to lstm\n",
    "        out = x.transpose(0,1)                           # reshape for lstm [seq_len, batch_size, inp_dim]\n",
    "        initData, data = out[:self.initSteps], out[self.initSteps:]  # initialization data and actual data to generate output\n",
    "        out, h1 = self.lstm1(initData)                  # initialize the hidden states with some data\n",
    "#         _, h2 = self.lstm2(out)\n",
    "        \n",
    "        out, _ = self.lstm1(data, h1)                         # get actual output to be use for prediction\n",
    "#         out, _ = self.lstm2(out, h2)\n",
    "        \n",
    "        # reshape and pass through fcn\n",
    "        out = out.transpose(0,1).contiguous().view(-1,self.hiddenDim)    # [(batch_size)*(seqLen-initSteps)) X hiddenDim]\n",
    "        out = self.fc1(out)                                              # [(batch_size)*(seqLen-initSteps)) X outDim]\n",
    "#         out = self.fc2(out)\n",
    "        \n",
    "        # reshape and return\n",
    "        out = out.view(batchSize, seqLen-self.initSteps,self.outDim) # batch_size x (seqLen-initSteps) X outDim\n",
    "        return(out)\n",
    "\n",
    "def loss_fn(outputs,labels,criterion):\n",
    "    _,_,outDim = outputs.shape\n",
    "    loss = criterion(outputs.contiguous().view(-1,outDim), labels.contiguous().view(-1))\n",
    "    return(loss)\n",
    "\n",
    "\n",
    "device = 'cuda:0'\n",
    "adversary = adversaryNet(inpDim=inpDim, hiddenDim=hiddenDim, outDim=outDim, initSteps=initSteps).to(device)\n",
    "\n",
    "# dataset\n",
    "traj_dataset = TrajDataset('out_files',6,2,10, mode = 'HDD')\n",
    "dataset_size = len(traj_dataset)\n",
    "val_size = int(val_frac*dataset_size)\n",
    "train_size = dataset_size - val_size\n",
    "print(train_size, val_size)\n",
    "train_dataset, val_dataset = random_split(traj_dataset, [train_size, val_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=10)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=10)\n",
    "\n",
    "# optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(adversary.parameters(), lr=learning_rate)\n",
    "lr_func = lambda e: 0.99**e\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_func)\n",
    "epochs = 100\n",
    "\n",
    "# tensorboard\n",
    "writer = SummaryWriter('runs/adversary_final_1lstm_1fc_lr_{}_lam_{}^e'.format(learning_rate,0.9))\n",
    "\n",
    "# train\n",
    "print('starting')\n",
    "t_start = time.time()\n",
    "for e in range(epochs):\n",
    "    loss_epoch, val_loss_epoch, c = 0, 0, 0\n",
    "    for X,Y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = adversary(X.to(device))\n",
    "        loss = loss_fn(outputs.to(device), Y.to(device), criterion)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch += loss.data\n",
    "        c += 1\n",
    "    loss_epoch /= c\n",
    "    writer.add_scalar('training loss', loss_epoch, e)\n",
    "    scheduler.step()\n",
    "    \n",
    "    c = 0\n",
    "    for X,Y in val_loader:\n",
    "        with torch.no_grad():\n",
    "            outputs = adversary(X.to(device))\n",
    "            loss = loss_fn(outputs.to(device), Y.to(device), criterion)\n",
    "            val_loss_epoch += loss.data\n",
    "            c += 1\n",
    "    val_loss_epoch /= c\n",
    "    writer.add_scalar('validation loss', val_loss_epoch, e)\n",
    "    print('Train loss {}, Val loss {}'.format(loss_epoch, val_loss_epoch))\n",
    "t_end = time.time()\n",
    "print('time taken {}'.format(t_end-t_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# visualize some results\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot(traj, leaderID, pred, leader_viz = True, fname = None):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    trajLen = traj.shape[0]\n",
    "    for i in range(nAgents):\n",
    "        if leader_viz and i == leaderID:\n",
    "            # init steps in grey\n",
    "            plt.plot(traj[:initSteps+1,i*2], traj[:initSteps+1,i*2+1], color = 'orange', alpha = 0.9)    # trajectory\n",
    "            # prediction steps - red if correct, black if wrong\n",
    "            for j in range(initSteps,trajLen-1):\n",
    "                color = 'red' if pred[j-initSteps] == leaderID else 'black'\n",
    "                plt.plot(traj[[j,j+1],i*2], traj[[j,j+1],i*2+1], color = color, alpha = 0.8, label = 'True')    \n",
    "            # add an arrow for direction\n",
    "            plt.arrow(traj[-2,i*2], traj[-2,i*2+1], traj[-1,i*2]-traj[-2,i*2], traj[-1,i*2+1]-traj[-2,i*2+1], head_width=0.03, head_length=0.03, color = color)\n",
    "        else:\n",
    "            plt.plot(traj[:,i*2], traj[:,i*2+1], color = 'blue', alpha = 0.2)    # trajectory\n",
    "            plt.arrow(traj[-2,i*2], traj[-2,i*2+1], traj[-1,i*2]-traj[-2,i*2], traj[-1,i*2+1]-traj[-2,i*2+1], head_width=0.03, head_length=0.03, color = 'blue', alpha = 0.3)\n",
    "    # legend\n",
    "    custom_lines = [Line2D([0], [0], color='orange', lw=4),\n",
    "                    Line2D([0], [0], color='red', lw=4),\n",
    "                    Line2D([0], [0], color='black', lw=4),\n",
    "                    Line2D([0], [0], color='blue', alpha = 0.3, lw=4)]\n",
    "    \n",
    "    plt.legend(custom_lines, ['Leader initial observation', 'Leader correct prediction', 'Leader wrong prediction', 'Followers'])\n",
    "    plt.xlabel('$X$')\n",
    "    plt.ylabel('$Y$')\n",
    "    plt.tight_layout()\n",
    "    if not fname is None:\n",
    "        plt.savefig(fname)\n",
    "\n",
    "paths = ['figures/uniform_viz', 'figures/leader_viz']\n",
    "for path in paths:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    \n",
    "for i, (traj, leader_id) in enumerate(val_dataset):\n",
    "    leader_id = leader_id[0].numpy()\n",
    "    with torch.no_grad():\n",
    "        out = adversary(traj.to(device).view(1,-1,obsDim*nAgents)).detach().cpu().numpy().reshape(-1,nAgents)\n",
    "        out = np.argmax(out, axis = 1)\n",
    "        \n",
    "    plot(traj, leader_id, pred = out, leader_viz = False, fname = 'figures/uniform_viz/uniform_viz_{}'.format(i))\n",
    "    plot(traj, leader_id, pred = out, leader_viz = True, fname = 'figures/leader_viz/leader_viz_{}'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # test dataloading time\n",
    "# print('Size of dataset {}'.format(sys.getsizeof(trajDataset.X)))\n",
    "\n",
    "# for i in range(len(trajDataset)):\n",
    "#     X,Y = trajDataset[i]\n",
    "\n",
    "\n",
    "    \n",
    "# 0.45 for HDD\n",
    "# 0.27 for SSD\n",
    "# 0.00035 for RAM\n",
    "\n",
    "#\n",
    "# 10 epochs (excluding dataloading time), with 10 worker\n",
    "# GPU, shuffling = True\n",
    "# 4.97 for RAM\n",
    "# 5.48 for SSD\n",
    "# 5.77 for HDD\n",
    "# \n",
    "# 13 for CPU\n",
    "\n",
    "# Conclusion\n",
    "# reading from SSD and HDD is similar, RAM is much faster\n",
    "# actual runtime for trining is very similar \n",
    "# workers are not making any difference\n",
    "# If I read files one by one myself it's slower that pytorch dataloader - because of parallel processes I believe\n",
    "# If I use batches from full data array stored in RAM, it's the fastest\n",
    "# Shuffling isn't taking time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# visualize data\n",
    "# a = np.random.random((3,3))\n",
    "# print(a)\n",
    "# print(a[[1,2],1])\n",
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.randn((10,2))\n",
    "torch.chunk(a,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "time 13.416211128234863\n"
     ]
    }
   ],
   "source": [
    "import gym, time, cv2, numpy as np, copy\n",
    "\n",
    "class Recorder(gym.Wrapper):\n",
    "    def __init__(self, env, fps = 30):\n",
    "        super(Recorder, self).__init__(env)\n",
    "        self.path = None\n",
    "        self.video = None\n",
    "        self.fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "        self.fps = fps\n",
    "    def startRecording(self, path):\n",
    "        self.path = path\n",
    "        frame = self.render(mode='rgb_array')\n",
    "        h,w,c = frame.shape\n",
    "        self.video = cv2.VideoWriter(self.path,self.fourcc, self.fps, (w,h))\n",
    "            \n",
    "    def recordFrame(self):\n",
    "        frame = self.render(mode='rgb_array')\n",
    "        temp = copy.deepcopy(frame[:,:,0])\n",
    "        frame[:,:,0] = frame[:,:,2]\n",
    "        frame[:,:,2] = temp\n",
    "        self.video.write(frame)\n",
    "    \n",
    "    def endVideo(self):\n",
    "        self.video.release()\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "env = myWrapper(env, fps=30)\n",
    "\n",
    "done = False\n",
    "env.reset()\n",
    "\n",
    "# help(env.render)\n",
    "t_start = time.time()\n",
    "# try recording 3 episodes\n",
    "for e in range(1):\n",
    "    env.startRecording('marlsave/{}.mp4'.format(e))\n",
    "    done = False\n",
    "    for i in range(400):\n",
    "#     while not done:\n",
    "        a = env.action_space.sample()\n",
    "        obs, rew, done, info = env.step(a)\n",
    "#         time.sleep(0.1)\n",
    "#         obs = env.render(mode='rgb_array', visible=False)\n",
    "        env.recordFrame()\n",
    "    env.endVideo()\n",
    "env.close()\n",
    "print('time', time.time()-t_start)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pyglet' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-91faaaf6cd0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# print(cv2.__version__)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pyglet' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "# help(type(cv2.VideoWriter))\n",
    "# print(cv2.__version__)\n",
    "import pyglet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-218893e14525>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# temp = a[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# temp.append(4)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# print(a)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.random.random((2,3))\n",
    "\n",
    "# temp = a[0]\n",
    "# temp.append(4)\n",
    "# print(a)\n",
    "# print(temp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PrivateFlocking",
   "language": "python",
   "name": "privateflocking"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
